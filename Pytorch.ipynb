{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.2755e-39, 1.0561e-38, 1.0286e-38],\n",
      "        [8.4490e-39, 1.0102e-38, 9.0919e-39],\n",
      "        [1.0102e-38, 8.9082e-39, 8.4489e-39],\n",
      "        [9.6429e-39, 8.4490e-39, 9.6429e-39],\n",
      "        [9.2755e-39, 1.0286e-38, 9.0919e-39]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6721, 0.2574, 0.0955],\n",
      "        [0.7201, 0.4864, 0.9038],\n",
      "        [0.0390, 0.4256, 0.7368],\n",
      "        [0.5942, 0.2011, 0.9855],\n",
      "        [0.2543, 0.2080, 0.1762]])\n"
     ]
    }
   ],
   "source": [
    "#randomly initialized matrix\n",
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "#construct a matrix filled wiht zeros with long datatype\n",
    "x = torch.zeros(5,3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "#construct a tensor directyly from data\n",
    "x = torch.tensor([5.5,3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-0.3752,  0.0270, -1.7324],\n",
      "        [-1.1739, -1.5896,  0.1725],\n",
      "        [-1.3745, -1.7261, -0.7349],\n",
      "        [ 1.6789,  1.3476, -0.3052],\n",
      "        [-0.0278,  1.1385, -0.3483]])\n"
     ]
    }
   ],
   "source": [
    "#create tensor based on an existing tensor. These methods will reuse properties of the input tensor\n",
    "# e.g dtype, unless new values are provided by user\n",
    "x = x.new_ones(5,3,dtype = torch.double)  #new_* methods take in sizes\n",
    "print(x)\n",
    "x = torch.randn_like(x, dtype=torch.float)     #override dtype!\n",
    "print(x)                                       # result has the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2088,  0.0325, -1.5197],\n",
      "        [-0.5401, -1.0705,  0.7391],\n",
      "        [-0.6993, -0.9224, -0.7262],\n",
      "        [ 1.7583,  1.5456,  0.1934],\n",
      "        [-0.0117,  1.5581,  0.2610]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2088,  0.0325, -1.5197],\n",
      "        [-0.5401, -1.0705,  0.7391],\n",
      "        [-0.6993, -0.9224, -0.7262],\n",
      "        [ 1.7583,  1.5456,  0.1934],\n",
      "        [-0.0117,  1.5581,  0.2610]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2088,  0.0325, -1.5197],\n",
       "        [-0.5401, -1.0705,  0.7391],\n",
       "        [-0.6993, -0.9224, -0.7262],\n",
       "        [ 1.7583,  1.5456,  0.1934],\n",
       "        [-0.0117,  1.5581,  0.2610]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.empty(5,3)\n",
    "torch.add(x,y, out=result)\n",
    "#print(result)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2088,  0.0325, -1.5197],\n",
      "        [-0.5401, -1.0705,  0.7391],\n",
      "        [-0.6993, -0.9224, -0.7262],\n",
      "        [ 1.7583,  1.5456,  0.1934],\n",
      "        [-0.0117,  1.5581,  0.2610]])\n"
     ]
    }
   ],
   "source": [
    "#add x to y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''Any operation that mutates a tensor in-place is post-fixed with an _. For example: x.copy_(y), x.t_(), will change x.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3752,  0.0270, -1.7324],\n",
       "        [-1.1739, -1.5896,  0.1725],\n",
       "        [-1.3745, -1.7261, -0.7349],\n",
       "        [ 1.6789,  1.3476, -0.3052],\n",
       "        [-0.0278,  1.1385, -0.3483]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0270, -1.5896, -1.7261,  1.3476,  1.1385])\n"
     ]
    }
   ],
   "source": [
    "print(x[:,1])\n",
    "#print(x[1,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.view\n",
    "If there is any situation that you don't know how many rows you want but are sure of the number of columns, then you can specify this with a -1. (Note that you can extend this to tensors with more dimensions. Only one of the axis value can be -1). This is a way of telling the library: \"give me a tensor that has these many columns and you compute the appropriate number of rows that is necessary to make this happen\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1662,  0.7501,  1.4537, -0.2377],\n",
      "        [-0.1699,  0.3264, -1.6596, -0.1646],\n",
      "        [ 0.0321,  1.4180, -0.6246, -0.7299],\n",
      "        [-0.6686, -0.5971, -0.3324, -1.4054]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([16]),\n",
       " tensor([[ 0.1662,  0.7501,  1.4537, -0.2377, -0.1699,  0.3264, -1.6596, -0.1646],\n",
       "         [ 0.0321,  1.4180, -0.6246, -0.7299, -0.6686, -0.5971, -0.3324, -1.4054]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Resizing/Reshaping the tensor\n",
    "x = torch.randn(4,4)\n",
    "print(x)\n",
    "y = x.view(16)\n",
    "z = x.view(-1,8)\n",
    "y.size(),z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1029])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1028614342212677"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you have only one element tensor, use .item() to the value as python scalars\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "x.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting a torch tensor to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting numpy array to torch tensor\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a)\n",
    "print(b)\n",
    "np.add(a,1,out=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOPE\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!\n",
    "else:\n",
    "    print('NOPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aamir\n"
     ]
    }
   ],
   "source": [
    "print('Aamir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOGRAD: AUTOMATIC DIFFERENTIATION\n",
    "The autograd package provides automatic differentiation for all operation on Tensor. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n",
    "\n",
    "#Tensor\n",
    "------\n",
    "torch.Tensor is central class of the package.\n",
    "If you set its attribute **.requires_grad()** as True, it starts to track all operation on it. When you finish your computtion you can call .backward() and have all the gradients computed automatically. The gradient for this tensor will be accumulated inot .grad attribute.\n",
    "\n",
    "To stop a tensor from tracking history, you can call **detach()** to detach it from the computation history,\n",
    "and to prevent future computation from being tracked.\n",
    "\n",
    "To prevent tracking history(and using memory), you can also wrap the code block with **torch.no_grad()**: This can be particularly helpful when evaluating a model because the model may have trainaible parameters with requires_grad=True, but for which we don't need the gradients.\n",
    "\n",
    "There is one more clas which is very important for aut0grad implementation a Function\n",
    "\n",
    "Tensor and Function are interconnected and build up and acyclic graph, that encodes a complete history of computation. Each tensor has a **.grad_fn** attribute that references a Function that has created the Tensor.\n",
    "\n",
    "If you want to compute the derivatives, you can call **.backward()** on a Tensor. If Tensor is scalar you don't need to specify any argumennts to backward(), however if it has more elements, you don't need to specify a gradient, but you need to speciy a gradient argument that is a tensor of matching shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<AddBackward0 object at 0x000001C2872C8348>\n"
     ]
    }
   ],
   "source": [
    "print(x.grad_fn)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y*y*3\n",
    "out = z.mean()\n",
    "print(z,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x000001C2872C3D08>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,2)\n",
    "a = ((a*3)/(a-1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a*a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradients**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s backprop now. Because **out** contains a single scalar, **out.backward()** is equivalent to **out.backward(torch.tensor(1.))**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print gradients d(out)/dx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -340.9655,  -371.3545, -1325.0345], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,requires_grad=True)\n",
    "y = x * 2\n",
    "while y.data.norm()<1000:\n",
    "    y=y*2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also stop autograd from tracking history on Tensor with **.require_grad=True** either\n",
    "by wrapping the code block in **with torch.no_grad()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x**2).requires_grad)\n",
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by using **.detach()** to get new Tensor with some content but \n",
    "that does not require gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "y = x.detach()\n",
    "print(y.requires_grad)\n",
    "print(x.eq(y).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28908520.949068658\n",
      "1 23467604.360672787\n",
      "2 24180917.356898397\n",
      "3 27002666.35619718\n",
      "4 28550498.96604411\n",
      "5 25857656.98739277\n",
      "6 19237609.258243036\n",
      "7 11752405.832338084\n",
      "8 6338364.31508195\n",
      "9 3297303.9644351555\n",
      "10 1821877.940887975\n",
      "11 1122950.040700867\n",
      "12 778875.7445060022\n",
      "13 592255.93558374\n",
      "14 478107.95307557227\n",
      "15 399650.0609622641\n",
      "16 340853.999475639\n",
      "17 294273.50134341273\n",
      "18 256055.60325623833\n",
      "19 224053.8768121822\n",
      "20 196932.41476286325\n",
      "21 173753.88637135288\n",
      "22 153835.66916082596\n",
      "23 136607.1900396084\n",
      "24 121657.15584547547\n",
      "25 108619.8864984327\n",
      "26 97210.87079362725\n",
      "27 87206.31840261898\n",
      "28 78402.41101166014\n",
      "29 70627.45804304184\n",
      "30 63747.25632857827\n",
      "31 57638.514810671135\n",
      "32 52204.18377443318\n",
      "33 47363.419667075956\n",
      "34 43037.30964485081\n",
      "35 39165.51339254706\n",
      "36 35694.79114108816\n",
      "37 32572.775689395705\n",
      "38 29762.548943030066\n",
      "39 27229.1400082502\n",
      "40 24942.82337302801\n",
      "41 22872.852175284796\n",
      "42 20996.880012215217\n",
      "43 19294.605288538925\n",
      "44 17748.64421685002\n",
      "45 16341.976654786355\n",
      "46 15061.15350928661\n",
      "47 13893.247725724772\n",
      "48 12826.594160853156\n",
      "49 11851.616057390267\n",
      "50 10959.262081219733\n",
      "51 10142.002439998596\n",
      "52 9392.692091263665\n",
      "53 8705.51088138224\n",
      "54 8075.104312108693\n",
      "55 7495.333325608382\n",
      "56 6961.672904185413\n",
      "57 6470.13658851693\n",
      "58 6016.976081026893\n",
      "59 5599.102284734007\n",
      "60 5213.19659776671\n",
      "61 4856.665916058274\n",
      "62 4527.086292214735\n",
      "63 4221.964458993052\n",
      "64 3939.5939476420454\n",
      "65 3677.8369044139195\n",
      "66 3435.1750690414005\n",
      "67 3210.0670774956993\n",
      "68 3001.049722870969\n",
      "69 2806.952066746153\n",
      "70 2626.646113163196\n",
      "71 2458.8711594671777\n",
      "72 2302.7603856997594\n",
      "73 2157.7134938379477\n",
      "74 2022.6478816528252\n",
      "75 1896.7152790397718\n",
      "76 1779.3215559290427\n",
      "77 1669.7714945080668\n",
      "78 1567.5339446925173\n",
      "79 1472.0523835894755\n",
      "80 1382.8235492188642\n",
      "81 1299.4364520987733\n",
      "82 1221.482452666166\n",
      "83 1148.5730074803062\n",
      "84 1080.3542801215767\n",
      "85 1016.4870541879263\n",
      "86 956.657524381562\n",
      "87 900.6053620403316\n",
      "88 848.0737059176117\n",
      "89 798.8322138221818\n",
      "90 752.6466380443346\n",
      "91 709.3159084833574\n",
      "92 668.6499023666142\n",
      "93 630.4701253096471\n",
      "94 594.6144530717745\n",
      "95 560.9299716597942\n",
      "96 529.2880098788931\n",
      "97 499.53870848941204\n",
      "98 471.58097546665624\n",
      "99 445.2898929943457\n",
      "100 420.5580182106756\n",
      "101 397.2939216352419\n",
      "102 375.37752969792064\n",
      "103 354.7463922321846\n",
      "104 335.3144434597349\n",
      "105 317.0040913576969\n",
      "106 299.75085877735853\n",
      "107 283.48821698907136\n",
      "108 268.15567310020595\n",
      "109 253.69817151556873\n",
      "110 240.06408084704253\n",
      "111 227.1977152414869\n",
      "112 215.05859487706087\n",
      "113 203.597493501297\n",
      "114 192.7791293674863\n",
      "115 182.5620951195933\n",
      "116 172.91209613309184\n",
      "117 163.79658987483305\n",
      "118 155.18464404885427\n",
      "119 147.04722284227174\n",
      "120 139.3566115504774\n",
      "121 132.0849706049398\n",
      "122 125.2086352256407\n",
      "123 118.70602362770089\n",
      "124 112.55694236893804\n",
      "125 106.738372692211\n",
      "126 101.23292183107867\n",
      "127 96.02312225662607\n",
      "128 91.09176377846305\n",
      "129 86.42534697622935\n",
      "130 82.00787141102276\n",
      "131 77.82338574086597\n",
      "132 73.8603903202714\n",
      "133 70.10704509017907\n",
      "134 66.55265619002932\n",
      "135 63.18336200003006\n",
      "136 59.991201546340164\n",
      "137 56.96563480222545\n",
      "138 54.09828274424623\n",
      "139 51.37954394281996\n",
      "140 48.803061396707896\n",
      "141 46.3593914632784\n",
      "142 44.0429731990405\n",
      "143 41.84493958757584\n",
      "144 39.7603576405198\n",
      "145 37.78265106529656\n",
      "146 35.90656835317282\n",
      "147 34.126281754273336\n",
      "148 32.43714457194645\n",
      "149 30.833879549515178\n",
      "150 29.31271488265875\n",
      "151 27.868278482697157\n",
      "152 26.496916654857614\n",
      "153 25.194910717903138\n",
      "154 23.958945888012174\n",
      "155 22.78518764383879\n",
      "156 21.670247288434698\n",
      "157 20.61126184346857\n",
      "158 19.605521463960855\n",
      "159 18.65012648152443\n",
      "160 17.742492060882068\n",
      "161 16.880092300312693\n",
      "162 16.060587589366083\n",
      "163 15.28177068233802\n",
      "164 14.541666332961956\n",
      "165 13.838254558317804\n",
      "166 13.169724415462415\n",
      "167 12.534288333909856\n",
      "168 11.930170878101702\n",
      "169 11.35587486646807\n",
      "170 10.809760170851277\n",
      "171 10.290419502873151\n",
      "172 9.79657305669248\n",
      "173 9.3269415865697\n",
      "174 8.880353612003123\n",
      "175 8.455541091805415\n",
      "176 8.051452931385287\n",
      "177 7.6671172828450835\n",
      "178 7.301565856554867\n",
      "179 6.95367317313573\n",
      "180 6.62270009320347\n",
      "181 6.307815691053273\n",
      "182 6.008134208980391\n",
      "183 5.722969488257511\n",
      "184 5.451605703149475\n",
      "185 5.193353129632684\n",
      "186 4.947544996974511\n",
      "187 4.713662117737941\n",
      "188 4.490984854827317\n",
      "189 4.278975341803196\n",
      "190 4.077161556830129\n",
      "191 3.885045343663249\n",
      "192 3.702117919344488\n",
      "193 3.5279459633071557\n",
      "194 3.3621224763930955\n",
      "195 3.204237492073072\n",
      "196 3.0539107538796135\n",
      "197 2.910708853048439\n",
      "198 2.7743265677736164\n",
      "199 2.644450525620359\n",
      "200 2.5207529129979283\n",
      "201 2.4029284429998334\n",
      "202 2.2906946822024215\n",
      "203 2.1837784152898667\n",
      "204 2.0819270326753347\n",
      "205 1.9849344027735591\n",
      "206 1.8924973023295715\n",
      "207 1.804424434869643\n",
      "208 1.720517886751998\n",
      "209 1.6405703120543338\n",
      "210 1.564383112236948\n",
      "211 1.4917851192014346\n",
      "212 1.422611637927143\n",
      "213 1.3566860887611538\n",
      "214 1.2938773800056125\n",
      "215 1.2340018885147468\n",
      "216 1.1769394230106078\n",
      "217 1.122544457995613\n",
      "218 1.0706956707095217\n",
      "219 1.0212786869782868\n",
      "220 0.9741679008590092\n",
      "221 0.9292619129301039\n",
      "222 0.886453665622798\n",
      "223 0.8456613169052838\n",
      "224 0.8067499566596092\n",
      "225 0.7696552460479251\n",
      "226 0.7342893178480911\n",
      "227 0.7005663739467813\n",
      "228 0.6684119240402749\n",
      "229 0.6377532426106345\n",
      "230 0.6085187387836037\n",
      "231 0.5806415995085479\n",
      "232 0.5540640449660104\n",
      "233 0.5287083986288776\n",
      "234 0.5045308697101294\n",
      "235 0.4814701468733179\n",
      "236 0.45947700189455115\n",
      "237 0.4384981517001221\n",
      "238 0.4184911576920437\n",
      "239 0.3994065234340899\n",
      "240 0.3812029912277326\n",
      "241 0.36384152072905085\n",
      "242 0.3472762976228271\n",
      "243 0.33147371889464583\n",
      "244 0.3163978160314142\n",
      "245 0.3020168168384971\n",
      "246 0.2882975284773386\n",
      "247 0.27520666215155737\n",
      "248 0.2627168458419916\n",
      "249 0.2508023937800842\n",
      "250 0.23943414888946313\n",
      "251 0.22858488570210875\n",
      "252 0.21823287137907038\n",
      "253 0.20835501282651833\n",
      "254 0.19892908067833245\n",
      "255 0.18993398257168903\n",
      "256 0.181349861116476\n",
      "257 0.17315751054625755\n",
      "258 0.16534100763456797\n",
      "259 0.1578803238425997\n",
      "260 0.15075903426570014\n",
      "261 0.14396221398050915\n",
      "262 0.13747561398958505\n",
      "263 0.13128343264253284\n",
      "264 0.12537310410733465\n",
      "265 0.1197319020498919\n",
      "266 0.11434693620161093\n",
      "267 0.10920796951524026\n",
      "268 0.10430132967729172\n",
      "269 0.09961764666095115\n",
      "270 0.09514578058481493\n",
      "271 0.09087662587435427\n",
      "272 0.08680085495239345\n",
      "273 0.08290954797843836\n",
      "274 0.07919446044575205\n",
      "275 0.07564802110173606\n",
      "276 0.07226212104549712\n",
      "277 0.06902873152500039\n",
      "278 0.06594149383784813\n",
      "279 0.06299334352147336\n",
      "280 0.060178213287620956\n",
      "281 0.057490253888240736\n",
      "282 0.054923306787715155\n",
      "283 0.05247210514804325\n",
      "284 0.050131823890199614\n",
      "285 0.04789671851901324\n",
      "286 0.04576208442945994\n",
      "287 0.043723361432799\n",
      "288 0.04177622398994016\n",
      "289 0.039916531765439245\n",
      "290 0.03814041231493536\n",
      "291 0.036444062592718415\n",
      "292 0.034823807727497554\n",
      "293 0.03327668584688743\n",
      "294 0.031798623623603244\n",
      "295 0.03038672018335882\n",
      "296 0.029038049808609412\n",
      "297 0.027749754912509247\n",
      "298 0.026519065241614095\n",
      "299 0.025343417275142537\n",
      "300 0.02422040147998924\n",
      "301 0.023147699273686893\n",
      "302 0.022122915872229636\n",
      "303 0.02114383430868621\n",
      "304 0.02020851887389181\n",
      "305 0.019314815805699673\n",
      "306 0.01846097528115956\n",
      "307 0.01764518446851795\n",
      "308 0.01686571665119601\n",
      "309 0.016120981719894747\n",
      "310 0.01540961439863363\n",
      "311 0.014729699876836994\n",
      "312 0.014080070643223525\n",
      "313 0.013459357363160744\n",
      "314 0.012866152067098097\n",
      "315 0.01229931726475592\n",
      "316 0.011757675132426504\n",
      "317 0.011240073403433165\n",
      "318 0.010745496373301102\n",
      "319 0.010272868953996778\n",
      "320 0.009821108717198004\n",
      "321 0.009389403975557343\n",
      "322 0.008976838699949304\n",
      "323 0.00858251893646686\n",
      "324 0.00820563941443666\n",
      "325 0.007845454629591068\n",
      "326 0.007501221435772075\n",
      "327 0.007172284761774925\n",
      "328 0.006857788766959135\n",
      "329 0.006557198664401364\n",
      "330 0.00626988390591486\n",
      "331 0.005995260630537679\n",
      "332 0.005732755103237248\n",
      "333 0.00548182062565894\n",
      "334 0.005241950237126887\n",
      "335 0.005012693242767298\n",
      "336 0.004793531796964097\n",
      "337 0.004583995527068974\n",
      "338 0.004383693795239987\n",
      "339 0.004192217008363599\n",
      "340 0.004009166042058374\n",
      "341 0.0038341663754928555\n",
      "342 0.0036668472850351404\n",
      "343 0.0035068842339721984\n",
      "344 0.0033539863528233896\n",
      "345 0.0032077694738805677\n",
      "346 0.003067966268234811\n",
      "347 0.0029343066115293036\n",
      "348 0.002806511150710282\n",
      "349 0.002684318098992755\n",
      "350 0.0025674818716101785\n",
      "351 0.002455777119689314\n",
      "352 0.002348970516318378\n",
      "353 0.0022468378361554424\n",
      "354 0.002149166631429014\n",
      "355 0.0020557704468188815\n",
      "356 0.0019664636471937984\n",
      "357 0.0018810621036426088\n",
      "358 0.0017993923335546322\n",
      "359 0.001721292257522129\n",
      "360 0.0016466091286687296\n",
      "361 0.001575206176070174\n",
      "362 0.00150689830567215\n",
      "363 0.001441573393922045\n",
      "364 0.0013791006190066036\n",
      "365 0.0013193527467343386\n",
      "366 0.001262207311327751\n",
      "367 0.0012075560504637452\n",
      "368 0.0011552840675812814\n",
      "369 0.0011053018997140558\n",
      "370 0.0010574861073467398\n",
      "371 0.0010117530996195314\n",
      "372 0.000968009381457054\n",
      "373 0.000926171144485318\n",
      "374 0.000886149888775008\n",
      "375 0.0008478688549804659\n",
      "376 0.0008112553893824722\n",
      "377 0.000776235543082208\n",
      "378 0.0007427331314645393\n",
      "379 0.0007106842491471842\n",
      "380 0.0006800276943180727\n",
      "381 0.0006507011165140615\n",
      "382 0.0006226478056345235\n",
      "383 0.0005958097311487514\n",
      "384 0.000570135003934202\n",
      "385 0.0005455755706811488\n",
      "386 0.0005220822398271308\n",
      "387 0.0004996028831316571\n",
      "388 0.0004780971637915485\n",
      "389 0.0004575229292886377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390 0.00043783973665931545\n",
      "391 0.00041900722799718254\n",
      "392 0.00040098974735705876\n",
      "393 0.0003837534015179692\n",
      "394 0.0003672635550018819\n",
      "395 0.0003514830412470171\n",
      "396 0.0003363848693194841\n",
      "397 0.00032193895590575735\n",
      "398 0.0003081169395572833\n",
      "399 0.00029489161575986045\n",
      "400 0.0002822372642342181\n",
      "401 0.00027012862822442453\n",
      "402 0.00025854464950753167\n",
      "403 0.0002474583728037605\n",
      "404 0.00023685003471529453\n",
      "405 0.0002266990829990971\n",
      "406 0.00021698552300931245\n",
      "407 0.0002076900656534485\n",
      "408 0.00019879483482071605\n",
      "409 0.00019028275795681613\n",
      "410 0.00018213856623982495\n",
      "411 0.00017434348005724716\n",
      "412 0.00016688396507548675\n",
      "413 0.00015974567033727704\n",
      "414 0.0001529138939548298\n",
      "415 0.00014637561630650276\n",
      "416 0.00014011870794858477\n",
      "417 0.00013413013894725257\n",
      "418 0.0001283997824518895\n",
      "419 0.00012291496195410414\n",
      "420 0.0001176652815190489\n",
      "421 0.0001126411408454205\n",
      "422 0.00010783253720918066\n",
      "423 0.00010323018417235174\n",
      "424 9.882513644238665e-05\n",
      "425 9.460902871447625e-05\n",
      "426 9.057431480129766e-05\n",
      "427 8.671210601349919e-05\n",
      "428 8.301541314687407e-05\n",
      "429 7.947703307801035e-05\n",
      "430 7.609011100375904e-05\n",
      "431 7.284812278395107e-05\n",
      "432 6.974507429389106e-05\n",
      "433 6.677483620420967e-05\n",
      "434 6.393192625716424e-05\n",
      "435 6.121046572593958e-05\n",
      "436 5.8605206795720886e-05\n",
      "437 5.611148351872356e-05\n",
      "438 5.372419564298634e-05\n",
      "439 5.1439001084946186e-05\n",
      "440 4.925148576156843e-05\n",
      "441 4.715739570880304e-05\n",
      "442 4.5153007404159764e-05\n",
      "443 4.3234028692205356e-05\n",
      "444 4.139688728540755e-05\n",
      "445 3.9638192403075896e-05\n",
      "446 3.7954495779549856e-05\n",
      "447 3.634262412710941e-05\n",
      "448 3.47995113194415e-05\n",
      "449 3.332234320593789e-05\n",
      "450 3.190823427934497e-05\n",
      "451 3.055424662925959e-05\n",
      "452 2.9257953679059668e-05\n",
      "453 2.8016904242833914e-05\n",
      "454 2.6828671106925757e-05\n",
      "455 2.5691020951747497e-05\n",
      "456 2.460183812595551e-05\n",
      "457 2.3559007494082628e-05\n",
      "458 2.2560702924278274e-05\n",
      "459 2.160480673875771e-05\n",
      "460 2.068954840186916e-05\n",
      "461 1.9813190438290803e-05\n",
      "462 1.897410903206288e-05\n",
      "463 1.817070526554253e-05\n",
      "464 1.740145489336869e-05\n",
      "465 1.6664896694870677e-05\n",
      "466 1.5959784830603234e-05\n",
      "467 1.528454904151654e-05\n",
      "468 1.4637934424453869e-05\n",
      "469 1.4018783701740748e-05\n",
      "470 1.3425927100871809e-05\n",
      "471 1.2858229430997947e-05\n",
      "472 1.2314634787574848e-05\n",
      "473 1.1794121677697555e-05\n",
      "474 1.1295769415261466e-05\n",
      "475 1.081847876796343e-05\n",
      "476 1.0361420869790019e-05\n",
      "477 9.923747530083794e-06\n",
      "478 9.504627409429493e-06\n",
      "479 9.103272629568729e-06\n",
      "480 8.718954144614768e-06\n",
      "481 8.350913180653361e-06\n",
      "482 7.998505982628136e-06\n",
      "483 7.660973312126497e-06\n",
      "484 7.337732295186059e-06\n",
      "485 7.028193895443314e-06\n",
      "486 6.731760261256793e-06\n",
      "487 6.447867394274651e-06\n",
      "488 6.175997762620067e-06\n",
      "489 5.9156398382066875e-06\n",
      "490 5.666300950953333e-06\n",
      "491 5.427480944585086e-06\n",
      "492 5.198760958435038e-06\n",
      "493 4.979710183287208e-06\n",
      "494 4.7699316194713165e-06\n",
      "495 4.56901313322501e-06\n",
      "496 4.376592104188457e-06\n",
      "497 4.192307178363872e-06\n",
      "498 4.015810986233817e-06\n",
      "499 3.846753406639762e-06\n"
     ]
    }
   ],
   "source": [
    "'''N is batch size; D_in is input dimension\n",
    "H is hidden dimension; D_out is output dimension'''\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(500):\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h,0)\n",
    "    #print(h_relu)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "    \n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(t,loss)\n",
    "    \n",
    "    #Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h<0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "    \n",
    "    #update weights\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.Tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.float32\n",
      "torch.strided\n"
     ]
    }
   ],
   "source": [
    "print(t.device)\n",
    "print(t.dtype)\n",
    "print(t.layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([1,2,3])\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor** is class contructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    .tensor is factory function builds tensor object. functions accepts as parameter input and returns a particular type of object. Factory function is an OOP concept which help in creating object instead from the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns Idnetity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.Tensor(data) #constructor\n",
    "t2 = torch.tensor(data) #factory func\n",
    "t3 = torch.as_tensor(data)#factory functions\n",
    "t4 = torch.from_numpy(data)#factory func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    " print(t1)\n",
    "print(t2)\n",
    "print(t3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int32\n",
      "torch.int32\n",
      "torch.int32\n"
     ]
    }
   ],
   "source": [
    " print(t1.dtype)\n",
    "print(t2.dtype)\n",
    "print(t3.dtype)\n",
    "print(t4.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dtype() infer based on the incoming data\n",
    "\n",
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor(data)\n",
    "t2 = torch.Tensor(data)\n",
    "t3 = torch.as_tensor(data)#takes any arraya\n",
    "t4 = torch.from_numpy(data)#in this case it only takes from numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]=0\n",
    "data[1]=0\n",
    "data[2]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0], dtype=torch.int32)\n",
      "tensor([0, 0, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(t3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **t1&t2** it cretes an additional copy where as in\n",
    "case of **t3&t4** it shares a data in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Operations\n",
    "1. Reshaping operations\n",
    "2. Element wise operation\n",
    "3. Reduction operation\n",
    "4. Access operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [1,1,1,1],\n",
    "    [2,2,2,2],\n",
    "    [3,3,3,3]\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(t.shape).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(1,12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 2., 2.],\n",
       "        [2., 2., 3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(2,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 2., 2.],\n",
       "        [2., 2., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [3., 3.],\n",
       "        [3., 3.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(6,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next way to change the shape is by **squezzing** and **unsquezing** them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Squeezing** a tensor removes all the axis that have a length of one while **unsqueezing** a tensor adds dimension with a length of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(t.reshape(1,12).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "print(t.reshape(1,12).squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(t.reshape(1,12).squeeze().unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "print(t.reshape(1,12).squeeze().unsqueeze(dim=0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since input tensor can be of any shape we pass the **-1** of reshape function -1 tells to figure out what the value should be based on the other value and the number of the value contained within the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    t = t.reshape(1,-1)\n",
    "    t = t.squeeze()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After squeezing the first axis is removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Flatten operation Visualized - Tensor batch procession for Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Pic.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1]\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = torch.tensor([\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = torch.tensor([\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 4])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.stack((t1,t2,t3))\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "t  = t.reshape(3,1,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 1, 1, 1],\n",
       "          [1, 1, 1, 1],\n",
       "          [1, 1, 1, 1],\n",
       "          [1, 1, 1, 1]]],\n",
       "\n",
       "\n",
       "        [[[2, 2, 2, 2],\n",
       "          [2, 2, 2, 2],\n",
       "          [2, 2, 2, 2],\n",
       "          [2, 2, 2, 2]]],\n",
       "\n",
       "\n",
       "        [[[3, 3, 3, 3],\n",
       "          [3, 3, 3, 3],\n",
       "          [3, 3, 3, 3],\n",
       "          [3, 3, 3, 3]]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(t.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.flatten(start_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.flatten(start_dim =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(3,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.broadcast_todcast_to(2,t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + torch.tensor(\n",
    "    np.broadcast_to(2,t.shape), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([\n",
    "    [1,2],\n",
    "    [2,3]\n",
    "\n",
    "    ],dtype=torch.float32\n",
    ")\n",
    "t2 = torch.tensor([2,4], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t1+t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "even though they have different dimension the elment wise opearion\n",
    "is possible. And braodcasting is what makes it possible.\n",
    "Lower rank **t2** transform into the higher rank tensor **t1** via broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.broadcast_to(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
